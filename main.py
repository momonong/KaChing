from node.query_optimize.graph import build_query_optimize_graph
from node.decide_fetch.graph import build_decide_fetch_graph
from node.explain.graph import build_explain_graph
from node.decide_fetch.convert import convert_to_stock_input
from node.explain.convert import convert_to_explain_state
from node.decide_fetch.model import StockState
from node.explain.model import ExplainState
from node.query_optimize.model import QueryState, QueryOutput

if __name__ == "__main__":
    # âœ… ä½¿ç”¨è€…è¼¸å…¥è‡ªç„¶èªè¨€
    user_query = "æˆ‘æƒ³çŸ¥é“å°ç©é›»æœ€è¿‘å¹¾å¤©çš„è‚¡åƒ¹èˆ‡ç‡Ÿæ”¶å¦‚ä½•"

    # ğŸ” Step 1: query_optimize
    query_optimize_app = build_query_optimize_graph()
    query_state = QueryState(query=user_query)
    query_result = query_optimize_app.invoke(query_state)
    query_state = QueryState(**dict(query_result))  # æ˜ç¢ºè½‰å‹
    parsed: QueryOutput = query_state.result

    print("ğŸ§  LLM parsed query:")
    print(parsed)

    # ğŸ“ˆ Step 2: decide_fetch
    fetch_app = build_decide_fetch_graph()
    query_dict = convert_to_stock_input(query_state)

    print("ğŸ“¤ è½‰æ›å¾Œçš„ query_dict:")
    print(query_dict)

    fetch_result = fetch_app.invoke(query_dict)

    print("ğŸ—‚ Raw fetch_result dict:")
    print(fetch_result)

    stock_state = StockState(**fetch_result)

    print("ğŸ“¥ StockState æ±ºç­–èˆ‡å…§å®¹:")
    print(stock_state)

    # ğŸ§  Step 3: explain
    explain_app = build_explain_graph()
    explain_input = convert_to_explain_state(stock_state)
    explain_result = explain_app.invoke(explain_input)
    explain_state = ExplainState(**explain_result)

    # âœ… è¼¸å‡ºçµæœ
    print("ğŸ“¦ æ‰€æœ‰ fetch_resultsï¼š")
    for key, df in explain_state.fetch_results.items():
        print(f"ğŸ”¹ {key}:")
        print("Shape:", df.shape)
        print(df)

    print("\nğŸ§  LLM Explanation:")
    print(explain_state.explanation)

